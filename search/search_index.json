{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Warning This documentation is a work in process, and is far from complete. Formulaic is a high-performance implementation of Wilkinson formulas for Python, which are very useful for transforming dataframes into a form suitable for ingestion into various modelling frameworks (especially linear regression). Source Code : https://github.com/matthewwardrop/formulaic Issue tracker : https://github.com/matthewwardrop/formulaic/issues Warning While this project is now fully functional, the API is still subject to change between major versions ( 0.<major>.<minor> ) as we continue to improve things. If you are going to depend on it in another project, it is advisable to pin formulaic to within a major version, for example: formulaic>=0.1.0,<0.2 . It provides: high-performance dataframe to model-matrix conversions. support for reusing the encoding choices made during conversion of one data-set on other datasets. extensible formula parsing. extensible data input/output plugins, with implementations for: input: pandas.DataFrame pyarrow.Table output: pandas.DataFrame numpy.ndarray scipy.sparse.CSCMatrix support for symbolic differentiation of formulas (and hence model matrices). with more to come! For some examples of what Formulaic provides, and how to use it, please refer to the Concepts and User Guides documentation.","title":"Introduction"},{"location":"changelog/","text":"For changes since the latest tagged release, please refer to the git commit log . 0.5.0 (28 Aug 2022) This is a major new release with some minor API changes, some ergonomic improvements, and a few bug fixes. Breaking changes: Accessing named substructures of Formula objects (e.g. formula.lhs ) no longer returns a list of terms; but rather a Formula object, so that the helper methods can remain accessible. You can access the raw terms by iterating over the formula ( list(formula) ) or looking up the root node ( formula.root ). New features and improvements: The ModelSpec object is now the source of truth in all ModelMatrix generations, and can be constructed directly from any supported specification using ModelSpec.from_spec(...) . Supported specifications include formula strings, parsed formulae, model matrices and prior model specs. The .get_model_matrix() helper methods across Formula , FormulaMaterializer , ModelSpec and model_matrix objects/helpers functions are now consistent, and all use ModelSpec directly under the hood. When accessing substructures of Formula objects (e.g. formula.lhs ), the term lists will be wrapped as trivial Formula instances rather than returned as raw lists (so that the helper methods like .get_model_matrix() can still be used). FormulaSpec is now exported from the top-level module. Bugfixes and cleanups: Fixed ModelSpec specifications being overriden by default arguments to FormulaMaterializer.get_model_matrix . Structured._flatten() now correctly flattens unnamed substructures. 0.4.0 (10 Aug 2022) This is a major new release with some new features, greatly improved ergonomics for structured formulae, matrices and specs, and a few small breaking changes (most with backward compatibility shims). All users are encouraged to upgrade. Breaking changes: include_intercept is no longer an argument to FormulaParser.get_terms ; and is instead an argument of the DefaultFormulaParser constructor. If you want to modify the include_intercept behaviour, please use: Formula ( \"y ~ x\" , _parser = DefaultFormulaParser ( include_intercept = False )) Accessing terms via Formula.terms is deprecated since Formula became a subclass of Structured[List[Terms]] . You can directly iterate over, and/or access nested structure on the Formula instance itself. Formula.terms has a deprecated property which will return a reference to itself in order to support legacy use-cases. This will be removed in 1.0.0. ModelSpec.feature_names and ModelSpec.feature_columns are deprecated in favour of ModelSpec.column_names and ModelSpec.column_indices . Deprecated properties remain in-place to support legacy use-cases. These will be removed in 1.0.0. New features and enhancements: Structured formulae (and their derived matrices and specs) are now mutable. Internally Formula has been refactored as a subclass of Structured[List[Terms]] , and can be incrementally built and modified. The matrix and spec outputs now have explicit subclasses of Structured ( ModelMatrices and ModelSpecs respectively) to expose convenience methods that allow these objects to be largely used interchangeably with their singular counterparts. ModelMatrices and ModelSpecs arenow surfaced as top-level exports of the formulaic module. Structured (and its subclasses) gained improved integration of nested tuple structure, as well as support for flattened iteration, explicit mapping output types, and lots of cleanups. ModelSpec was made into a dataclass, and gained several new properties/methods to support better introspection and mutation of the model spec. FormulaParser was renamed DefaultFormulaParser , and made a subclass of the new formula parser interface FormulaParser . In this process include_intercept was removed from the API, and made an instance attribute of the default parser implementation. Bugfixes and cleanups: Fixed AST evaluation for large formulae that caused the evaluation to hit the recursion limit. Fixed sparse categorical encoding when the dataframe index is not the standard range index. Fixed a bug in the linear constraints parser when more than two constraints were specified in a comma-separated string. Avoid implicit changing of the sparsity structure of CSC matrices. If manually constructed ModelSpec s are provided by the user during materialization, they are updated to reflect the output-type chosen by the user, as well as whether to ensure full rank/etc. Allowed use of older pandas versions. All versions >=1.0.0 are now supported. Various linting cleanups as pylint was added to the CI testing. Documentation: Apart from the .materializer submodule, most code now has inline documentation and annotations. 0.3.4 (1 May 2022) This is a backward compatible major release that adds several new features. New features and enhancements: Added support for customizing the contrasts generated for categorical features, including treatment, sum, deviation, helmert and custom contrasts. Added support for the generation of linear constraints for ModelMatrix instances (see ModelMatrix.model_spec.get_linear_constraints ). Added support for passing ModelMatrix , ModelSpec and other formula-like objects to the model_matrix sugar method so that pre-processed formulae can be used. Improved the way tokens are manipulated for the right-hand-side intercept and substitutions of 0 with -1 to avoid substitutions in quoted contexts. Bugfixes and cleanups: Fixed variable sanitization during evaluation, allowing variables with special characters to be used in Python transforms; for example: bs(`my|feature%is^cool`) . Fixed the parsing of dictionaries and sets within python expressions in the formula; for example: C(x, {\"a\": [1,2,3]}) . Bumped requirement on astor to >=0.8 to fix issues with ast-generation in Python 3.8+ when numerical constants are present in the parsed python expression (e.g. \"bs(x, df=10)\"). 0.3.3 (4 April 2022) This is a minor patch release that migrates the package tooling to poetry ; solving a version inconsistency when packaging for conda . 0.3.2 (17 March 2022) This is a minor patch release that fixes an attempt to import numpy.typing when numpy is not version 1.20 or later. 0.3.1 (15 March 2022) This is a minor patch release that fixes the maintaining of output types, NA-handling, and assurance of full-rank for factors that evaluate to pre-encoded columns when constructing a model matrix from a pre-defined ModelSpec. The benchmarks were also updated. 0.3.0 (14 March 2022) This is a major new release with many new features, and a few small breaking changes. All users are encouraged to upgrade. Breaking changes: The minimum supported version of Python is now 3.7 (up from 3.6). Moved transform implementations from formulaic.materializers.transforms to the top-level formulaic.transforms module, and ported all existing transforms to output FactorValues types rather than dictionaries. FactorValues is an object proxy that allows output types like pandas.DataFrame s to be used as they normally would, with some additional metadata for formulaic accessible via the __formulaic_metadata__ attribute. This makes non-formula direct usage of these transforms much more pleasant. ~ is no longer a generic formula separator, and can only be used once in a formula. Please use the newly added | operator to separate a formula into multiple parts. New features and enhancements: Added support for \"structured\" formulas, and updated the ~ operator to use them. Structured formulas can have named substructures, for example: lhs and rhs for the ~ operator. The representation of formulas has been updated to show this structure. Added support for context-sensitivity during the resolution of operators, allowing more flexible operators to be implemented (this is exploited by the | operator which splits formulas into multiple parts). The formulaic.model_matrix syntactic sugar function now accepts ModelSpec and ModelMatrix instances as the \"formula\" spec, making generation of matrices with the same form as previously generated matrices more convenient. Added the poly transform (compatible with R and patsy). numpy is now always available in formulas via np , allowing formulas like np.sum(x) . For convenience, log , log10 , log2 , exp , exp10 and exp2 are now exposed as transforms independent of user context. Pickleability is now guaranteed and tested via unit tests. Failure to pickle any formulaic metadata object (such as formulas, model specs, etc) is considered a bug. The capturing of user context for use in formula materialization has been split out into a utility method formulaic.utils.context.capture_context() . This can be used by libraries that wrap Formulaic to capture the variables and/or transforms available in a users' environment where appropriate. Bugfixes and cleanups: Migrated all code to use the Black style. Increased unit testing coverage to 100%. Fixed mis-alignment in the right- and left-hand sides of formulas if there were nulls at different indices. Fixed basis spline transforms ignoring state, fixed generated splines for large numbers of knots, and fixed specification of knots via non-list datatypes. Fixed category order being inconsistent if categories are explicitly ordered differently in the underlying data. Lots of other minor nits and cleanups. Documentation: The structure of the docsite has been improved (but is still incomplete). The .parser and .utils modules of Formulaic are now inline documented and annotated. 0.2.4 (9 July 2021) This is a minor release that fixes an issue whereby the ModelSpec instances attached to ModelMatrix objects would keep reference to the original data, greatly inflating the size of the ModelSpec. 0.2.3 (4 February 2021) This release is identical to v0.2.2, except that the source distribution now includes the docs, license, and tox configuration. 0.2.2 (4 February 2021) This is a minor release with one bugfix. Fix pandas model matrix outputs when constants are generated as part of model matrix construction and the incoming dataframe has a custom rather than range index. 0.2.1 (22 January 2021) This is a minor patch release that brings in some valuable improvements. Keep track of the pandas dataframe index if outputting a pandas DataFrame . Fix using functions in formulae that are nested within a module or class. Avoid crashing when an attempt is made to generate an empty model matrix. Enriched setup.py with long description for a better experience on PyPI. 0.2.0 (21 January 2021) This is major release that brings in a large number of improvements, with a huge number of commits. Some API breakage from the experimental 0.1.x series is likely in various edge-cases. Highlights include: Enriched formula parser to support quoting, and evaluation of formulas involving fields with invalid Python names. Added commonly used stateful transformations (identity, center, scale, bs) Improved the helpfulness of error messages reported by the formula parser. Added support for basic calculus on formulas (useful when taking the gradient of linear models). Made it easier to extend Formulaic with additional materializers. Many internal improvements to code quality and reliability, including 100% test coverage. Added benchmarks for Formulaic against R and patsy. Added documentation. Miscellaneous other bugfixes and cleanups. 0.1.2 (6 November 2019) Performance improvements around the encoding of categorical features. Matthew Wardrop (1): Improve the performance of encoding operations. 0.1.1 (31 October 2019) No code changes here, just a verification that GitHub CI integration was working. Matthew Wardrop (1): Update Github workflow triggers. 0.1.0 (31 October 2019) This release added support for keeping track of encoding choices during model matrix generation, so that they can be reused on similarly structured data. It also added comprehensive unit testing and CI integration using GitHub actions. Matthew Wardrop (5): Add support for stateful transforms (including encoding). Fix tokenizing of nested Python function calls. Add support for nested transforms that return multiple columns, as well as passing through of materializer config through to transforms. Add comprehensive unit testing along with several small miscellaneous bug fixes and improvements. Add GitHub actions configuration. 0.0.1 (1 September 2019) Initial open sourcing of formulaic . Matthew Wardrop (1): Initial (mostly) working implementation of Wilkinson formulas.","title":"Changelog"},{"location":"changelog/#050-28-aug-2022","text":"This is a major new release with some minor API changes, some ergonomic improvements, and a few bug fixes. Breaking changes: Accessing named substructures of Formula objects (e.g. formula.lhs ) no longer returns a list of terms; but rather a Formula object, so that the helper methods can remain accessible. You can access the raw terms by iterating over the formula ( list(formula) ) or looking up the root node ( formula.root ). New features and improvements: The ModelSpec object is now the source of truth in all ModelMatrix generations, and can be constructed directly from any supported specification using ModelSpec.from_spec(...) . Supported specifications include formula strings, parsed formulae, model matrices and prior model specs. The .get_model_matrix() helper methods across Formula , FormulaMaterializer , ModelSpec and model_matrix objects/helpers functions are now consistent, and all use ModelSpec directly under the hood. When accessing substructures of Formula objects (e.g. formula.lhs ), the term lists will be wrapped as trivial Formula instances rather than returned as raw lists (so that the helper methods like .get_model_matrix() can still be used). FormulaSpec is now exported from the top-level module. Bugfixes and cleanups: Fixed ModelSpec specifications being overriden by default arguments to FormulaMaterializer.get_model_matrix . Structured._flatten() now correctly flattens unnamed substructures.","title":"0.5.0 (28 Aug 2022)"},{"location":"changelog/#040-10-aug-2022","text":"This is a major new release with some new features, greatly improved ergonomics for structured formulae, matrices and specs, and a few small breaking changes (most with backward compatibility shims). All users are encouraged to upgrade. Breaking changes: include_intercept is no longer an argument to FormulaParser.get_terms ; and is instead an argument of the DefaultFormulaParser constructor. If you want to modify the include_intercept behaviour, please use: Formula ( \"y ~ x\" , _parser = DefaultFormulaParser ( include_intercept = False )) Accessing terms via Formula.terms is deprecated since Formula became a subclass of Structured[List[Terms]] . You can directly iterate over, and/or access nested structure on the Formula instance itself. Formula.terms has a deprecated property which will return a reference to itself in order to support legacy use-cases. This will be removed in 1.0.0. ModelSpec.feature_names and ModelSpec.feature_columns are deprecated in favour of ModelSpec.column_names and ModelSpec.column_indices . Deprecated properties remain in-place to support legacy use-cases. These will be removed in 1.0.0. New features and enhancements: Structured formulae (and their derived matrices and specs) are now mutable. Internally Formula has been refactored as a subclass of Structured[List[Terms]] , and can be incrementally built and modified. The matrix and spec outputs now have explicit subclasses of Structured ( ModelMatrices and ModelSpecs respectively) to expose convenience methods that allow these objects to be largely used interchangeably with their singular counterparts. ModelMatrices and ModelSpecs arenow surfaced as top-level exports of the formulaic module. Structured (and its subclasses) gained improved integration of nested tuple structure, as well as support for flattened iteration, explicit mapping output types, and lots of cleanups. ModelSpec was made into a dataclass, and gained several new properties/methods to support better introspection and mutation of the model spec. FormulaParser was renamed DefaultFormulaParser , and made a subclass of the new formula parser interface FormulaParser . In this process include_intercept was removed from the API, and made an instance attribute of the default parser implementation. Bugfixes and cleanups: Fixed AST evaluation for large formulae that caused the evaluation to hit the recursion limit. Fixed sparse categorical encoding when the dataframe index is not the standard range index. Fixed a bug in the linear constraints parser when more than two constraints were specified in a comma-separated string. Avoid implicit changing of the sparsity structure of CSC matrices. If manually constructed ModelSpec s are provided by the user during materialization, they are updated to reflect the output-type chosen by the user, as well as whether to ensure full rank/etc. Allowed use of older pandas versions. All versions >=1.0.0 are now supported. Various linting cleanups as pylint was added to the CI testing. Documentation: Apart from the .materializer submodule, most code now has inline documentation and annotations.","title":"0.4.0 (10 Aug 2022)"},{"location":"changelog/#034-1-may-2022","text":"This is a backward compatible major release that adds several new features. New features and enhancements: Added support for customizing the contrasts generated for categorical features, including treatment, sum, deviation, helmert and custom contrasts. Added support for the generation of linear constraints for ModelMatrix instances (see ModelMatrix.model_spec.get_linear_constraints ). Added support for passing ModelMatrix , ModelSpec and other formula-like objects to the model_matrix sugar method so that pre-processed formulae can be used. Improved the way tokens are manipulated for the right-hand-side intercept and substitutions of 0 with -1 to avoid substitutions in quoted contexts. Bugfixes and cleanups: Fixed variable sanitization during evaluation, allowing variables with special characters to be used in Python transforms; for example: bs(`my|feature%is^cool`) . Fixed the parsing of dictionaries and sets within python expressions in the formula; for example: C(x, {\"a\": [1,2,3]}) . Bumped requirement on astor to >=0.8 to fix issues with ast-generation in Python 3.8+ when numerical constants are present in the parsed python expression (e.g. \"bs(x, df=10)\").","title":"0.3.4 (1 May 2022)"},{"location":"changelog/#033-4-april-2022","text":"This is a minor patch release that migrates the package tooling to poetry ; solving a version inconsistency when packaging for conda .","title":"0.3.3 (4 April 2022)"},{"location":"changelog/#032-17-march-2022","text":"This is a minor patch release that fixes an attempt to import numpy.typing when numpy is not version 1.20 or later.","title":"0.3.2 (17 March 2022)"},{"location":"changelog/#031-15-march-2022","text":"This is a minor patch release that fixes the maintaining of output types, NA-handling, and assurance of full-rank for factors that evaluate to pre-encoded columns when constructing a model matrix from a pre-defined ModelSpec. The benchmarks were also updated.","title":"0.3.1 (15 March 2022)"},{"location":"changelog/#030-14-march-2022","text":"This is a major new release with many new features, and a few small breaking changes. All users are encouraged to upgrade. Breaking changes: The minimum supported version of Python is now 3.7 (up from 3.6). Moved transform implementations from formulaic.materializers.transforms to the top-level formulaic.transforms module, and ported all existing transforms to output FactorValues types rather than dictionaries. FactorValues is an object proxy that allows output types like pandas.DataFrame s to be used as they normally would, with some additional metadata for formulaic accessible via the __formulaic_metadata__ attribute. This makes non-formula direct usage of these transforms much more pleasant. ~ is no longer a generic formula separator, and can only be used once in a formula. Please use the newly added | operator to separate a formula into multiple parts. New features and enhancements: Added support for \"structured\" formulas, and updated the ~ operator to use them. Structured formulas can have named substructures, for example: lhs and rhs for the ~ operator. The representation of formulas has been updated to show this structure. Added support for context-sensitivity during the resolution of operators, allowing more flexible operators to be implemented (this is exploited by the | operator which splits formulas into multiple parts). The formulaic.model_matrix syntactic sugar function now accepts ModelSpec and ModelMatrix instances as the \"formula\" spec, making generation of matrices with the same form as previously generated matrices more convenient. Added the poly transform (compatible with R and patsy). numpy is now always available in formulas via np , allowing formulas like np.sum(x) . For convenience, log , log10 , log2 , exp , exp10 and exp2 are now exposed as transforms independent of user context. Pickleability is now guaranteed and tested via unit tests. Failure to pickle any formulaic metadata object (such as formulas, model specs, etc) is considered a bug. The capturing of user context for use in formula materialization has been split out into a utility method formulaic.utils.context.capture_context() . This can be used by libraries that wrap Formulaic to capture the variables and/or transforms available in a users' environment where appropriate. Bugfixes and cleanups: Migrated all code to use the Black style. Increased unit testing coverage to 100%. Fixed mis-alignment in the right- and left-hand sides of formulas if there were nulls at different indices. Fixed basis spline transforms ignoring state, fixed generated splines for large numbers of knots, and fixed specification of knots via non-list datatypes. Fixed category order being inconsistent if categories are explicitly ordered differently in the underlying data. Lots of other minor nits and cleanups. Documentation: The structure of the docsite has been improved (but is still incomplete). The .parser and .utils modules of Formulaic are now inline documented and annotated.","title":"0.3.0 (14 March 2022)"},{"location":"changelog/#024-9-july-2021","text":"This is a minor release that fixes an issue whereby the ModelSpec instances attached to ModelMatrix objects would keep reference to the original data, greatly inflating the size of the ModelSpec.","title":"0.2.4 (9 July 2021)"},{"location":"changelog/#023-4-february-2021","text":"This release is identical to v0.2.2, except that the source distribution now includes the docs, license, and tox configuration.","title":"0.2.3 (4 February 2021)"},{"location":"changelog/#022-4-february-2021","text":"This is a minor release with one bugfix. Fix pandas model matrix outputs when constants are generated as part of model matrix construction and the incoming dataframe has a custom rather than range index.","title":"0.2.2 (4 February 2021)"},{"location":"changelog/#021-22-january-2021","text":"This is a minor patch release that brings in some valuable improvements. Keep track of the pandas dataframe index if outputting a pandas DataFrame . Fix using functions in formulae that are nested within a module or class. Avoid crashing when an attempt is made to generate an empty model matrix. Enriched setup.py with long description for a better experience on PyPI.","title":"0.2.1 (22 January 2021)"},{"location":"changelog/#020-21-january-2021","text":"This is major release that brings in a large number of improvements, with a huge number of commits. Some API breakage from the experimental 0.1.x series is likely in various edge-cases. Highlights include: Enriched formula parser to support quoting, and evaluation of formulas involving fields with invalid Python names. Added commonly used stateful transformations (identity, center, scale, bs) Improved the helpfulness of error messages reported by the formula parser. Added support for basic calculus on formulas (useful when taking the gradient of linear models). Made it easier to extend Formulaic with additional materializers. Many internal improvements to code quality and reliability, including 100% test coverage. Added benchmarks for Formulaic against R and patsy. Added documentation. Miscellaneous other bugfixes and cleanups.","title":"0.2.0 (21 January 2021)"},{"location":"changelog/#012-6-november-2019","text":"Performance improvements around the encoding of categorical features. Matthew Wardrop (1): Improve the performance of encoding operations.","title":"0.1.2 (6 November 2019)"},{"location":"changelog/#011-31-october-2019","text":"No code changes here, just a verification that GitHub CI integration was working. Matthew Wardrop (1): Update Github workflow triggers.","title":"0.1.1 (31 October 2019)"},{"location":"changelog/#010-31-october-2019","text":"This release added support for keeping track of encoding choices during model matrix generation, so that they can be reused on similarly structured data. It also added comprehensive unit testing and CI integration using GitHub actions. Matthew Wardrop (5): Add support for stateful transforms (including encoding). Fix tokenizing of nested Python function calls. Add support for nested transforms that return multiple columns, as well as passing through of materializer config through to transforms. Add comprehensive unit testing along with several small miscellaneous bug fixes and improvements. Add GitHub actions configuration.","title":"0.1.0 (31 October 2019)"},{"location":"changelog/#001-1-september-2019","text":"Initial open sourcing of formulaic . Matthew Wardrop (1): Initial (mostly) working implementation of Wilkinson formulas.","title":"0.0.1 (1 September 2019)"},{"location":"installation/","text":"The latest release of formulaic is always published to the Python Package Index (PyPI), from which it is available to download @ https://pypi.org/project/formulaic/ . If your Python environment is provisioned with pip , installing formulaic from the PyPI is as simple as running: $ pip install formulaic Note If you have a non-standard setup, ensure that pip above are replaced with the executables corresponding to the environment for which you are interested in installing formulaic . This is done automatically if you are using a virtual environment. You are ready to use Formulaic. To get introduced to the concepts underpinning Formulaic, please review the Concepts documentation, or to jump straight to how to use Formulaic, please review the User Guides documentation. Installing for development If you are interested in developing formulaic , you should clone the source code repository, and install in editable mode from there (allowing your changes to be instantly available to all new Python sessions). To clone the source code, run: $ git clone git@github.com:matthewwardrop/formulaic.git Note This requires you to have a GitHub account set up. If you do not have an account you can replace the SSH url above with https://github.com/matthewwardrop/formulaic.git . Also, if you are planning to submit your work upstream, you may wish to fork the repository into your own namespace first, and clone from there. To install in editable mode, run: $ pip install -e <path_to_cloned_formulaic_repo> You will need pip>=21.3 in order for this to work. You can then make any changes you like to the repo, and have them be reflected in your local Python sessions. Happy hacking, and I look forward to your contributions! Dependencies are managed using Poetry , and if you need to add a dependency, please use poetry add ... , which will ensure consistency of testing environments/etc.","title":"Installation"},{"location":"installation/#installing-for-development","text":"If you are interested in developing formulaic , you should clone the source code repository, and install in editable mode from there (allowing your changes to be instantly available to all new Python sessions). To clone the source code, run: $ git clone git@github.com:matthewwardrop/formulaic.git Note This requires you to have a GitHub account set up. If you do not have an account you can replace the SSH url above with https://github.com/matthewwardrop/formulaic.git . Also, if you are planning to submit your work upstream, you may wish to fork the repository into your own namespace first, and clone from there. To install in editable mode, run: $ pip install -e <path_to_cloned_formulaic_repo> You will need pip>=21.3 in order for this to work. You can then make any changes you like to the repo, and have them be reflected in your local Python sessions. Happy hacking, and I look forward to your contributions! Dependencies are managed using Poetry , and if you need to add a dependency, please use poetry add ... , which will ensure consistency of testing environments/etc.","title":"Installing for development"},{"location":"concepts/","text":"In this portion of Formulaic's documentation, we introduce the high-level concepts behind formulas, where they are useful, and how to use the implementation of formulas provided by formulaic . If you are unfamiliar with formulas, a brief introduction is provided in the What are formulas? section. If you are already familiar, you can skip forward to the Formula Grammar and User Guides . For a more detailed description of how Formulaic parses and materializes formulas, as well as how to augment and/or control this behavior, please refer to the Advanced Usage sections.","title":"Introduction"},{"location":"concepts/formulas/","text":"This section introduces the basic notions and origins of formulas. If you are already familiar with formulas from another context, you might want to skip forward to the Formula Grammer or User Guides . Origins Formulas were originally proposed by Wilkinson et al. 1 to aid in the description of ANOVA problems, but were popularised by the S language (and then R , as an implementation of S) in the context of linear regression. Since then they have been extended in R , and implemented in Python (by patsy ), in MATLAB , in Julia , and quite conceivably elsewhere. Each implementation has its own nuances and grammatical extensions, including Formulaic's which are described more completely in the Formula Grammar section of this manual. Why are they useful? Formulas are useful because they provide a concise and explicit specification for how data should be prepared for a model. Typically, the raw input data for a model is stored in a dataframe, but the actual implementations of various statistical methodologies (e.g. linear regression solvers) act on two-dimensional numerical matrices that go by several names depending on the prevailing nomenclature of your field, including \"model matrices\", \"design matrices\" and \"regressor matrices\" (within Formulaic, we refer to them as \"model matrices\"). A formula provides the necessary information required to automate much of the translation of a dataframe into a model matrix suitable for ingestion into a statistical model. Suppose, for example, that you have a dataframe with \\(N\\) rows and three numerical columns labelled: y , a and b . You would like to construct a linear regression model for y based on a , b and their interaction: \\[ y = \\alpha + \\beta_a a + \\beta_b b + \\beta_{ab} ab + \\varepsilon \\] with \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)\\). Rather than manually constructing the required matrices to pass to the regression solver, you could specify a formula of form: y ~ a + b + a:b When furnished with this formula and the dataframe, Formulaic (or indeed any other formula implementation) would generate two model matrix objects: an \\( N \\times 1 \\) matrix \\(Y\\) for the response variable y , and an \\( N \\times 4 \\) matrix \\(X\\) for the input columns intercept , a , b , and a * b . You can then directly pass these matrices to your regression solver, which internally will solve for \\(\\beta\\) in: \\[ Y = X\\beta + \\varepsilon. \\] The true value of formulas becomes more apparent as model complexity increases, where they can be a huge time-saver. For example: ~ (f1 + f2 + f3) * (x1 + x2 + scale(x3)) tells the formula interpreter to consider 16 fields of input data, corresponding to an intercept (1), each of the f* fields (3), each of the x* fields (3), and the combination of each f with each x (9). It also instructs the materializer to ensure that the x3 column is rescaled during the model matrix materialization phase such that it has mean zero and standard error of 1. If any of these columns is categorical in nature, they would by default also be one-hot/dummy encoded. Depending on the formula interpreter (including Formulaic), extra steps would also be taken to ensure that the resulting model matrix is structurally full-rank. As an added bonus, some formula implementations (including Formulaic) can remember any choices made during the materialization process, and apply them to consistently to new data, making it possible to easily generate new data that conforms to the same structure as the training data. For example, the scale(...) transform in the example above makes use of the mean and variance of the column to be scaled. Any future data should, however, should not undergo scaling based on its own mean and variance, but rather on the mean and variance that was measured for the training data set (otherwise the new dataset will not be consistent with the expectations of the trained model which will be interpreting it). Limitations Formulas are a very flexible tool, and can be augmented with arbitrary user-defined transforms. However, some transformations required by certain models may be more elegantly defined via a pre-formula dataframe operation or post-formula model matrix operation. Another consideration is that the default encoding and materialization choices for data are aligned with linear regression. If you are using a tree model, for example, you may not be interested in dummy encoding of \"categorical\" features, and this type of transform would have to be explicitly noted in the formula. Nevertheless, even in these cases, formulas are an excellent tool, and can often be used to greatly simplify data preparation workflows. Where to from here? To learn about the full set of features supported by the formula language as implemented by Formulaic, please review the Formula Grammar . To get a feel for how you can use formulaic to transform your dataframes into model matrices, please review the Quickstart . For more advanced use-cases, such as overriding or customising the implementations of formula parsing, please refer to the Advanced Usage section. Wilkinson, G. N., and C. E. Rogers. Symbolic description of factorial models for analysis of variance. J. Royal Statistics Society 22, pp. 392\u2013399, 1973. \u21a9","title":"What are formulas?"},{"location":"concepts/formulas/#origins","text":"Formulas were originally proposed by Wilkinson et al. 1 to aid in the description of ANOVA problems, but were popularised by the S language (and then R , as an implementation of S) in the context of linear regression. Since then they have been extended in R , and implemented in Python (by patsy ), in MATLAB , in Julia , and quite conceivably elsewhere. Each implementation has its own nuances and grammatical extensions, including Formulaic's which are described more completely in the Formula Grammar section of this manual.","title":"Origins"},{"location":"concepts/formulas/#why-are-they-useful","text":"Formulas are useful because they provide a concise and explicit specification for how data should be prepared for a model. Typically, the raw input data for a model is stored in a dataframe, but the actual implementations of various statistical methodologies (e.g. linear regression solvers) act on two-dimensional numerical matrices that go by several names depending on the prevailing nomenclature of your field, including \"model matrices\", \"design matrices\" and \"regressor matrices\" (within Formulaic, we refer to them as \"model matrices\"). A formula provides the necessary information required to automate much of the translation of a dataframe into a model matrix suitable for ingestion into a statistical model. Suppose, for example, that you have a dataframe with \\(N\\) rows and three numerical columns labelled: y , a and b . You would like to construct a linear regression model for y based on a , b and their interaction: \\[ y = \\alpha + \\beta_a a + \\beta_b b + \\beta_{ab} ab + \\varepsilon \\] with \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)\\). Rather than manually constructing the required matrices to pass to the regression solver, you could specify a formula of form: y ~ a + b + a:b When furnished with this formula and the dataframe, Formulaic (or indeed any other formula implementation) would generate two model matrix objects: an \\( N \\times 1 \\) matrix \\(Y\\) for the response variable y , and an \\( N \\times 4 \\) matrix \\(X\\) for the input columns intercept , a , b , and a * b . You can then directly pass these matrices to your regression solver, which internally will solve for \\(\\beta\\) in: \\[ Y = X\\beta + \\varepsilon. \\] The true value of formulas becomes more apparent as model complexity increases, where they can be a huge time-saver. For example: ~ (f1 + f2 + f3) * (x1 + x2 + scale(x3)) tells the formula interpreter to consider 16 fields of input data, corresponding to an intercept (1), each of the f* fields (3), each of the x* fields (3), and the combination of each f with each x (9). It also instructs the materializer to ensure that the x3 column is rescaled during the model matrix materialization phase such that it has mean zero and standard error of 1. If any of these columns is categorical in nature, they would by default also be one-hot/dummy encoded. Depending on the formula interpreter (including Formulaic), extra steps would also be taken to ensure that the resulting model matrix is structurally full-rank. As an added bonus, some formula implementations (including Formulaic) can remember any choices made during the materialization process, and apply them to consistently to new data, making it possible to easily generate new data that conforms to the same structure as the training data. For example, the scale(...) transform in the example above makes use of the mean and variance of the column to be scaled. Any future data should, however, should not undergo scaling based on its own mean and variance, but rather on the mean and variance that was measured for the training data set (otherwise the new dataset will not be consistent with the expectations of the trained model which will be interpreting it).","title":"Why are they useful?"},{"location":"concepts/formulas/#limitations","text":"Formulas are a very flexible tool, and can be augmented with arbitrary user-defined transforms. However, some transformations required by certain models may be more elegantly defined via a pre-formula dataframe operation or post-formula model matrix operation. Another consideration is that the default encoding and materialization choices for data are aligned with linear regression. If you are using a tree model, for example, you may not be interested in dummy encoding of \"categorical\" features, and this type of transform would have to be explicitly noted in the formula. Nevertheless, even in these cases, formulas are an excellent tool, and can often be used to greatly simplify data preparation workflows.","title":"Limitations"},{"location":"concepts/formulas/#where-to-from-here","text":"To learn about the full set of features supported by the formula language as implemented by Formulaic, please review the Formula Grammar . To get a feel for how you can use formulaic to transform your dataframes into model matrices, please review the Quickstart . For more advanced use-cases, such as overriding or customising the implementations of formula parsing, please refer to the Advanced Usage section. Wilkinson, G. N., and C. E. Rogers. Symbolic description of factorial models for analysis of variance. J. Royal Statistics Society 22, pp. 392\u2013399, 1973. \u21a9","title":"Where to from here?"},{"location":"concepts/grammar/","text":"This section of the documentation describes the formula grammar used by Formulaic. It is almost identical that used by patsy and R, and so most formulas should work without modification. However, there are some differences, which are called out below. Operators In this section, we introduce a complete list of the grammatical operators that you can use by default in your formulas. They are listed such that each section (demarcated by \"-----\") has higher precedence then the block that follows. When you write a formula involving several operators of different precedence, those with higher precedence will be resolved first. \"Arity\" is the number of arguments the operator takes. Within operators of the same precedence, all binary operators are evaluated from left to right (they are left-associative). To highlight differences in grammar betweeh formulaic, patsy and R, we highlight any differences below. If there is a checkmark the Formulaic, Patsy and R columns, then the grammar is consistent across all three, unless otherwise indicated. Operator Arity Description Formulaic Patsy R \"...\" 1 1 String literal. \u2713 \u2713 \u2717 [0-9]+\\.[0-9]+ 1 1 Numerical literal. \u2713 \u2717 \u2717 `...` 1 1 Quotes fieldnames within the incoming dataframe, allowing the use of special characters, e.g. `my|special$column!` \u2713 \u2717 \u2713 {...} 1 1 Quotes python operations, as a more convenient way to do Python operations than I(...) , e.g. {`my|col`**2} \u2713 \u2717 \u2717 <function>(...) 1 1 Python transform on column, e.g. my_func(x) which is equivalent to {my_func(x)} \u2713 2 \u2713 \u2717 ----- (...) 1 Groups operations, overriding normal precedence rules. All operations with the parentheses are performed before the result of these operations is permitted to be operated upon by its peers. \u2713 \u2713 \u2713 ----- ** 2 Includes all n-th order interactions of the terms in the left operand, where n is the (integral) value of the right operand, e.g. (a+b+c)**2 is equivalent to a + b + c + a:b + a:c + b:c . \u2713 \u2713 \u2713 ^ 2 Alias for ** . \u2717 \u2717 3 \u2713 ----- : 2 Adds a new term that corresponds to the interaction of its operands (i.e. their elementwise product). \u2713 \u2713 \u2713 ----- * 2 Includes terms for each of the additive and interactive effects of the left and right operands, e.g. a * b is equivalent to a + b + a:b . \u2713 \u2713 \u2713 / 2 Adds terms describing nested effects. It expands to the addition of a new term for the left operand and the interaction of all left operand terms with the right operand, i.e a / b is equivalent to a + a:b , (a + b) / c is equivalent to a + b + a:b:c , and a/(b+c) is equivalent to a + a:b + a:c . 4 \u2713 \u2713 \u2713 %in% 2 Alias for / . \u2717 \u2717 \u2713 ----- + 2 Adds a new term to the set of features. \u2713 \u2713 \u2713 - 2 Removes a term from the set of features (if present). \u2713 \u2713 \u2713 + 1 Returns the current term unmodified (not very useful). \u2713 \u2713 \u2713 - 1 Negates a term (only implemented for 0, in which case it is replaced with 1 ). \u2713 \u2713 \u2713 ----- | 2 Splits a formula into multiple parts, allowing the simultaneous generation of multiple model matrices. When on the right-hand-side of the ~ operator, all parts will attract an additional intercept term by default. \u2713 \u2717 \u2713 5 ----- ~ 1,2 Separates the target features from the input features. If absent, it is assumed that we are considering only the the input features. Unless otherwise indicated, it is assumed that the input features implicitly include an intercept. \u2713 \u2713 \u2713 Transforms Formulaic supports arbitrary transforms, any of which can also preserve state so that new data can undergo the same transformation as that used during modelling. The currently implemented transforms are shown below. Commonly used transforms that have not been implemented by formualaic are explicitly noted also. Transform Description Formulaic Patsy R I(...) Identity transform, allowing arbitrary Python/R operations, e.g. I(x+y) . Note that in formulaic , it is more idiomatic to use {x+y} . \u2713 \u2713 \u2713 C(...) Categorically encode a column, e.g. C(x) \u2713 \u2713 \u2713 center(...) Shift column data so mean is zero. \u2713 \u2713 \u2717 scale(...) Shift column so mean is zero and variance is 1. \u2713 \u2713 6 \u2713 standardize(...) Alias of scale . \u2717 \u2713 \u2717 poly(...) Generates a polynomial basis, allowing non-linear fits. \u2713 \u2717 \u2713 bs(...) Generates a B-Spline basis, allowing non-linear fits. \u2713 \u2713 \u2713 cr(...) Generates a natural cubic spline basis, allowing non-linear fits. \u2717 \u2713 \u2713 cc(...) Generates a cyclic cubic spline basis, allowing non-linear fits. \u2717 \u2713 \u2713 te(...) Generates a tensor product smooth. \u2717 \u2713 \u2713 ... Others? Contributions welcome! ? ? ? Tip Any function available in the context dictionary will also be available as transform, along with some commonly used functions imported from numpy: log , log10 , log2 , exp , exp10 , and exp2 . In addition the numpy module is always available as np . Thus, formulas like: log(y) ~ x + 10 will always do the right thing, even when these functions have not been made available in the user namespace. Note Formulaic does not (yet) support including extra terms in the formula that will not result in additions to the dataframe, for example model annotations like R's offset(...) . Behaviours and Conventions Beyond the formula operator grammar itself there are some differing behaviours and conventions of which you should be aware. Formulaic follows Patsy and then enhanced Formula R package in that both sides of the ~ operator are treated considered to be using the formula grammar, with the only difference being that the right hand side attracts an intercept by default. In vanilla R, the left hand side is treated as R code (and so x + y ~ z would result in a single column on the left-hand-side). You can recover vanilla R's behaviour by nesting the operations in a Python operator block (as described in the operator table): {y1 + y2} ~ a + b . Formula terms in Formulaic are always sorted first by the order of the interaction, and then alphabetically. In R and patsy, this second ordering is done in the order that columns were introduced to the formula (patsy additionally sorts by which fields are involved in the interactions). As a result formulas generated by formulaic with the same set of fields will always generate the same model matrix. Formulaic follows patsy's more rigourous handling of whether or not to include an intercept term. In R, b-1 and (b-1) both do not have an intercept, whereas in Formulaic and Patsy the parentheses are resolved first, and so the first does not have an intercept and the second does (because and implicit '1 +' is added prepended to the right hand side of the formula). Formulaic borrows a clever algorithm introduced by Patsy to carefully choose where to reduce the rank of the model matrix in order to ensure that the matrix is structurally full rank. This avoids producing over-specified model matrices in contexts that R would (since it only considers local full-rank structure, rather than global structure). You can read more about this in Patsy's documentation . This \"operator\" is actually part of the tokenisation process. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9 Formulaic additionally supports quoted fields with special characters, e.g. my_func(`my|special+column`) . \u21a9 The caret operator is not supported, but will not cause an error. It is ignored by the patsy formula parser, and treated as XOR Python operation on column. \u21a9 This somewhat confusing operator is useful when you want to include hierachical features in your data, and where certain interaction terms do not make sense (particularly in ANOVA contexts). For example, if a represents countries, and b represents cities, then the full product of terms from a * b === a + b + a:b does not make sense, because any value of b is guaranteed to coincide with a value in a , and does not independently add value. Thus, the operation a / b === a + a:b results in more sensible dataset. As a result, the / operator is right-distributive, since if b and c were both nested in a , you would want a/(b+c) === a + a:b + a:c . Likewise, the operator is not left-distributive, since if c is nested under both a and b separately, then you want (a + b)/c === a + b + a:b:c . Lastly, if c is nested in b , and b is nested in a , then you would want a/b/c === a + a:(b/c) === a + a:b + a:b:c . \u21a9 Implemented by an R package called Formula that extends the default formula syntax. \u21a9 Patsy uses the rescale keyword rather than scale , but provides the same functionality. \u21a9","title":"Formula Grammar"},{"location":"concepts/grammar/#operators","text":"In this section, we introduce a complete list of the grammatical operators that you can use by default in your formulas. They are listed such that each section (demarcated by \"-----\") has higher precedence then the block that follows. When you write a formula involving several operators of different precedence, those with higher precedence will be resolved first. \"Arity\" is the number of arguments the operator takes. Within operators of the same precedence, all binary operators are evaluated from left to right (they are left-associative). To highlight differences in grammar betweeh formulaic, patsy and R, we highlight any differences below. If there is a checkmark the Formulaic, Patsy and R columns, then the grammar is consistent across all three, unless otherwise indicated. Operator Arity Description Formulaic Patsy R \"...\" 1 1 String literal. \u2713 \u2713 \u2717 [0-9]+\\.[0-9]+ 1 1 Numerical literal. \u2713 \u2717 \u2717 `...` 1 1 Quotes fieldnames within the incoming dataframe, allowing the use of special characters, e.g. `my|special$column!` \u2713 \u2717 \u2713 {...} 1 1 Quotes python operations, as a more convenient way to do Python operations than I(...) , e.g. {`my|col`**2} \u2713 \u2717 \u2717 <function>(...) 1 1 Python transform on column, e.g. my_func(x) which is equivalent to {my_func(x)} \u2713 2 \u2713 \u2717 ----- (...) 1 Groups operations, overriding normal precedence rules. All operations with the parentheses are performed before the result of these operations is permitted to be operated upon by its peers. \u2713 \u2713 \u2713 ----- ** 2 Includes all n-th order interactions of the terms in the left operand, where n is the (integral) value of the right operand, e.g. (a+b+c)**2 is equivalent to a + b + c + a:b + a:c + b:c . \u2713 \u2713 \u2713 ^ 2 Alias for ** . \u2717 \u2717 3 \u2713 ----- : 2 Adds a new term that corresponds to the interaction of its operands (i.e. their elementwise product). \u2713 \u2713 \u2713 ----- * 2 Includes terms for each of the additive and interactive effects of the left and right operands, e.g. a * b is equivalent to a + b + a:b . \u2713 \u2713 \u2713 / 2 Adds terms describing nested effects. It expands to the addition of a new term for the left operand and the interaction of all left operand terms with the right operand, i.e a / b is equivalent to a + a:b , (a + b) / c is equivalent to a + b + a:b:c , and a/(b+c) is equivalent to a + a:b + a:c . 4 \u2713 \u2713 \u2713 %in% 2 Alias for / . \u2717 \u2717 \u2713 ----- + 2 Adds a new term to the set of features. \u2713 \u2713 \u2713 - 2 Removes a term from the set of features (if present). \u2713 \u2713 \u2713 + 1 Returns the current term unmodified (not very useful). \u2713 \u2713 \u2713 - 1 Negates a term (only implemented for 0, in which case it is replaced with 1 ). \u2713 \u2713 \u2713 ----- | 2 Splits a formula into multiple parts, allowing the simultaneous generation of multiple model matrices. When on the right-hand-side of the ~ operator, all parts will attract an additional intercept term by default. \u2713 \u2717 \u2713 5 ----- ~ 1,2 Separates the target features from the input features. If absent, it is assumed that we are considering only the the input features. Unless otherwise indicated, it is assumed that the input features implicitly include an intercept. \u2713 \u2713 \u2713","title":"Operators"},{"location":"concepts/grammar/#transforms","text":"Formulaic supports arbitrary transforms, any of which can also preserve state so that new data can undergo the same transformation as that used during modelling. The currently implemented transforms are shown below. Commonly used transforms that have not been implemented by formualaic are explicitly noted also. Transform Description Formulaic Patsy R I(...) Identity transform, allowing arbitrary Python/R operations, e.g. I(x+y) . Note that in formulaic , it is more idiomatic to use {x+y} . \u2713 \u2713 \u2713 C(...) Categorically encode a column, e.g. C(x) \u2713 \u2713 \u2713 center(...) Shift column data so mean is zero. \u2713 \u2713 \u2717 scale(...) Shift column so mean is zero and variance is 1. \u2713 \u2713 6 \u2713 standardize(...) Alias of scale . \u2717 \u2713 \u2717 poly(...) Generates a polynomial basis, allowing non-linear fits. \u2713 \u2717 \u2713 bs(...) Generates a B-Spline basis, allowing non-linear fits. \u2713 \u2713 \u2713 cr(...) Generates a natural cubic spline basis, allowing non-linear fits. \u2717 \u2713 \u2713 cc(...) Generates a cyclic cubic spline basis, allowing non-linear fits. \u2717 \u2713 \u2713 te(...) Generates a tensor product smooth. \u2717 \u2713 \u2713 ... Others? Contributions welcome! ? ? ? Tip Any function available in the context dictionary will also be available as transform, along with some commonly used functions imported from numpy: log , log10 , log2 , exp , exp10 , and exp2 . In addition the numpy module is always available as np . Thus, formulas like: log(y) ~ x + 10 will always do the right thing, even when these functions have not been made available in the user namespace. Note Formulaic does not (yet) support including extra terms in the formula that will not result in additions to the dataframe, for example model annotations like R's offset(...) .","title":"Transforms"},{"location":"concepts/grammar/#behaviours-and-conventions","text":"Beyond the formula operator grammar itself there are some differing behaviours and conventions of which you should be aware. Formulaic follows Patsy and then enhanced Formula R package in that both sides of the ~ operator are treated considered to be using the formula grammar, with the only difference being that the right hand side attracts an intercept by default. In vanilla R, the left hand side is treated as R code (and so x + y ~ z would result in a single column on the left-hand-side). You can recover vanilla R's behaviour by nesting the operations in a Python operator block (as described in the operator table): {y1 + y2} ~ a + b . Formula terms in Formulaic are always sorted first by the order of the interaction, and then alphabetically. In R and patsy, this second ordering is done in the order that columns were introduced to the formula (patsy additionally sorts by which fields are involved in the interactions). As a result formulas generated by formulaic with the same set of fields will always generate the same model matrix. Formulaic follows patsy's more rigourous handling of whether or not to include an intercept term. In R, b-1 and (b-1) both do not have an intercept, whereas in Formulaic and Patsy the parentheses are resolved first, and so the first does not have an intercept and the second does (because and implicit '1 +' is added prepended to the right hand side of the formula). Formulaic borrows a clever algorithm introduced by Patsy to carefully choose where to reduce the rank of the model matrix in order to ensure that the matrix is structurally full rank. This avoids producing over-specified model matrices in contexts that R would (since it only considers local full-rank structure, rather than global structure). You can read more about this in Patsy's documentation . This \"operator\" is actually part of the tokenisation process. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9 Formulaic additionally supports quoted fields with special characters, e.g. my_func(`my|special+column`) . \u21a9 The caret operator is not supported, but will not cause an error. It is ignored by the patsy formula parser, and treated as XOR Python operation on column. \u21a9 This somewhat confusing operator is useful when you want to include hierachical features in your data, and where certain interaction terms do not make sense (particularly in ANOVA contexts). For example, if a represents countries, and b represents cities, then the full product of terms from a * b === a + b + a:b does not make sense, because any value of b is guaranteed to coincide with a value in a , and does not independently add value. Thus, the operation a / b === a + a:b results in more sensible dataset. As a result, the / operator is right-distributive, since if b and c were both nested in a , you would want a/(b+c) === a + a:b + a:c . Likewise, the operator is not left-distributive, since if c is nested under both a and b separately, then you want (a + b)/c === a + b + a:b:c . Lastly, if c is nested in b , and b is nested in a , then you would want a/b/c === a + a:(b/c) === a + a:b + a:b:c . \u21a9 Implemented by an R package called Formula that extends the default formula syntax. \u21a9 Patsy uses the rescale keyword rather than scale , but provides the same functionality. \u21a9","title":"Behaviours and Conventions"},{"location":"guides/","text":"","title":"Introduction"},{"location":"guides/advanced/","text":"Coming soon!","title":"Advanced Usage"},{"location":"guides/quickstart/","text":"This document provides high-level documentation on how to get started using Formulaic. For deeper documentation about the internals, please refer to the Advanced Usage documentation. Building Model Matrices In formulaic , the simplest way to build your model matrices is to use the high-level model_matrix function: import pandas from formulaic import model_matrix df = pandas . DataFrame ({ 'y' : [ 0 , 1 , 2 ], 'a' : [ 'A' , 'B' , 'C' ], 'b' : [ 0.3 , 0.1 , 0.2 ], }) y , X = model_matrix ( \"y ~ a + b + a:b\" , df ) # This is short-hand for: # y, X = formulaic.Formula('y ~ a + b + a:b').get_model_matrix(df) # This lower-level API discussed in the Advanced Usage documentation. y = y 0 0 1 1 2 2 X = Intercept a[T.B] a[T.C] b a[T.B]:b a[T.C]:b 0 1.0 0 0 0.3 0.0 0.0 1 1.0 1 0 0.1 0.1 0.0 2 1.0 0 1 0.2 0.0 0.2 You will notice that the categorical values for a have been one-hot (aka dummy) encoded, and to ensure structural full-rankness of X 1 , one level has been dropped from a . For more details about how this guarantees that the matrix is full-rank, please refer to the excellent patsy documentation . If you are not using the model matrices for regression, and don't care if the matrix is not full-rank, you can pass ensure_full_rank=False : X = model_matrix(\"a + b + a:b\", df, ensure_full_rank=False) X = Intercept a[T.A] a[T.B] a[T.C] b a[T.A]:b a[T.B]:b a[T.C]:b 0 1.0 1 0 0 0.3 0.3 0.0 0.0 1 1.0 0 1 0 0.1 0.0 0.1 0.0 2 1.0 0 0 1 0.2 0.0 0.0 0.2 Note that the dropped level in a has been restored. Sparse Model Matrices By default, the generated model matrices are dense. In some case, particularly in large datasets with many categorical features, dense model matrices become hugely memory inefficient (since most entries of the data will be zero). Formulaic allows you to directly generate sparse model matrices using: X = model_matrix(\"a + b + a:b\", df, output='sparse') In this example, X is a \\( 6 \\times 3 \\) scipy.sparse.csc_matrix instance. X must be full-rank in order for the regression algorithm to invert a matrix derived from X . \u21a9","title":"Quickstart"},{"location":"guides/quickstart/#building-model-matrices","text":"In formulaic , the simplest way to build your model matrices is to use the high-level model_matrix function: import pandas from formulaic import model_matrix df = pandas . DataFrame ({ 'y' : [ 0 , 1 , 2 ], 'a' : [ 'A' , 'B' , 'C' ], 'b' : [ 0.3 , 0.1 , 0.2 ], }) y , X = model_matrix ( \"y ~ a + b + a:b\" , df ) # This is short-hand for: # y, X = formulaic.Formula('y ~ a + b + a:b').get_model_matrix(df) # This lower-level API discussed in the Advanced Usage documentation. y = y 0 0 1 1 2 2 X = Intercept a[T.B] a[T.C] b a[T.B]:b a[T.C]:b 0 1.0 0 0 0.3 0.0 0.0 1 1.0 1 0 0.1 0.1 0.0 2 1.0 0 1 0.2 0.0 0.2 You will notice that the categorical values for a have been one-hot (aka dummy) encoded, and to ensure structural full-rankness of X 1 , one level has been dropped from a . For more details about how this guarantees that the matrix is full-rank, please refer to the excellent patsy documentation . If you are not using the model matrices for regression, and don't care if the matrix is not full-rank, you can pass ensure_full_rank=False : X = model_matrix(\"a + b + a:b\", df, ensure_full_rank=False) X = Intercept a[T.A] a[T.B] a[T.C] b a[T.A]:b a[T.B]:b a[T.C]:b 0 1.0 1 0 0 0.3 0.3 0.0 0.0 1 1.0 0 1 0 0.1 0.0 0.1 0.0 2 1.0 0 0 1 0.2 0.0 0.0 0.2 Note that the dropped level in a has been restored.","title":"Building Model Matrices"},{"location":"guides/quickstart/#sparse-model-matrices","text":"By default, the generated model matrices are dense. In some case, particularly in large datasets with many categorical features, dense model matrices become hugely memory inefficient (since most entries of the data will be zero). Formulaic allows you to directly generate sparse model matrices using: X = model_matrix(\"a + b + a:b\", df, output='sparse') In this example, X is a \\( 6 \\times 3 \\) scipy.sparse.csc_matrix instance. X must be full-rank in order for the regression algorithm to invert a matrix derived from X . \u21a9","title":"Sparse Model Matrices"},{"location":"reference/","text":"","title":"Introduction"},{"location":"reference/api/","text":"Coming soon.","title":"API"}]}